# Sqldiag
**Sqldiag** is a robust forecasting framework that allows a DBMS to predict execute time for unknown workload based on historical data,
The prediction is based on similarity of unknown queries and historical queries. We do not use execute-plan since achieving execute-plan
will claim resource on user database, also inapplicable for __OLTP__ workload. Framework pipeline is:
* pre-process: templatize historical queries, fetch feature and label for training.
* auto-encode: train an adaptive encoding model using LSTM neural network. encode historical data.
* cluster: group query templates with similar encoded vector **cluster**s. Build **time-series predict model** for each cluster. 
  We used _K-means_ for **clustering** and _linear regression_ for **time-series prediction**. 
* predict: fit unknown query by trained model and return predicted execute time.

## Run forecasting on demo workload:
    python test/test_demo.py
We provide an example of the workload execution time forecasting for a sample subset of **TPCC** workload.
The prediction specified in demo train data and test data in [demo directory](test/data/). 
[training file](test/data/train.csv) and [test file](test/data/test.csv) present the format for input log file and to-be-predicted workload file.

![result](result.png)
## Dependencies

    python3.5+
    tensorflow<2.0.0
    keras
    sklearn
    matplotlib
    numpy

## Usage
## Training
If this is your first time using Sqldiag, you should prepare training data, format is:

    TIMER_START    |   TIMER_END   |   LOCK_TIME   |   WAIT_TIME   |   SQL_TEXT
*  _TIMER_START_: timestamp when current query executed.
*  _TIMER_END_: timestamp when current query finished.
*  _LOCK_TIME_: time which current query been locked.
*  _WAIT_TIME_: time which current query waited before execute.
*  _SQL_TEXT_: current query string.
*  Interval symbol during every 2 columns is **'\t|\t'**, if you cannot provide some columns on any line, just set them as 0.
*  You can modify hyper-parameters about clustering process at ```Cluster class``` in ```src/cluster.py ``` file to 
   fit your own dataset.

Run following command start training:

    python src/main.py train [--train LOG_FILE] [--model MODEL_DIR]
    
*  _LOG_FILE_: training data file directory.
*  _MODEL_DIR_: directory you want to save the models generated by training. Models will be used in prediction.
*  Training Epoch and batch size can be modified in **train** function in [main.py](src/main.py).
   If training succeed, you will see **"Train complete!"** on your screen. 
*  Best cluster number and typical query template for each cluster are returned by **train** function.

Run demo training as:

    python src/main.py train --train test/data/train.csv --model test/data/
                   
## Predict
Before prediction, you should ensure training completed at least one time. To-be-predicted queries should be arranged into a file, 
which each row contains one independent query. Run following command for prediction:
        
    python src/main.py predict [--model MODEL_DIR] [--predict WORKLOAD_FILE] [--ratio RETRAIN_RATIO]
    
*  _MODEL_DIR_: model directory, should be same with parameter in training.
*  _WORKLOAD_FILE_: To-be-predicted SQL file directory.
*  _RETRAIN_RATIO_: ratio for Sqldiag suggesting model-retrain. Default value is 0.5, means that if the number of 
   untrained elements in _WORKLOAD_FILE_ more than half of the number of trained elements in current model, Sqldiag will
   suggest you retrain your model with new training data. You will see 
   **"Ratio of new data has reached your set threshold, suggest re-training!"** on screen. 
   Prediction at this time will continue with using the model you trained last time.
*  Predict result is a list of float value, _nth_ value means the predicted execute time for the query at _nth_ row in _WORKLOAD_FILE_.
   Result will display on your screen, and also be returned. 
   
Run demo prediction as:

    python src/main.py predict --model test/data/ --predict test/data/test.csv --ratio 0.2
    

## Quick start
You can run training and predict at one time, command is:

    python src/main.py all [--train LOG_FILE] [--model MODEL_DIR]
                       [--predict WORKLOAD_FILE] [--ratio RETRAIN_RATIO]
                       
Run demo quick start as:
    
    python src/main.py all --train test/data/train.csv --model test/data/ --predict test/data/test.csv --ratio 0.2
    
Full usage:

    cd src
    python main.py [-h] [--train TRAIN] [--model MODEL] [--predict PREDICT]
                   [--ratio RATIO] {all,train,predict}